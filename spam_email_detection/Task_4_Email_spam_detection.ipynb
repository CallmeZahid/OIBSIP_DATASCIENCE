{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f326f178",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f326f178",
        "outputId": "adb60dc8-d7fb-4a7c-f8eb-8f1b6596fe32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f27fb810",
      "metadata": {
        "id": "f27fb810"
      },
      "outputs": [],
      "source": [
        "#reading of csv file\n",
        "df = pd.read_csv('spam.csv',encoding = \"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "158f4236",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "158f4236",
        "outputId": "1609f71b-bb30-4259-f810-77e568226bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email spam detection dataset is: \n",
            "         v1                                                 v2 Unnamed: 2  \\\n",
            "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
            "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
            "...    ...                                                ...        ...   \n",
            "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
            "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
            "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
            "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
            "5571   ham                         Rofl. Its true to its name        NaN   \n",
            "\n",
            "     Unnamed: 3 Unnamed: 4  \n",
            "0           NaN        NaN  \n",
            "1           NaN        NaN  \n",
            "2           NaN        NaN  \n",
            "3           NaN        NaN  \n",
            "4           NaN        NaN  \n",
            "...         ...        ...  \n",
            "5567        NaN        NaN  \n",
            "5568        NaN        NaN  \n",
            "5569        NaN        NaN  \n",
            "5570        NaN        NaN  \n",
            "5571        NaN        NaN  \n",
            "\n",
            "[5572 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "#Displaying dataset\n",
        "print(\"Email spam detection dataset is: \\n\",df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e319c760",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e319c760",
        "outputId": "0cccc8fa-432a-46e4-8fac-1271b1a35961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 rows of the dataset are: \n",
            "      v1                                                 v2 Unnamed: 2  \\\n",
            "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
            "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n",
            "2        NaN        NaN  \n",
            "3        NaN        NaN  \n",
            "4        NaN        NaN  \n",
            "\n",
            "\n",
            "Bottom 5 rows of the dataset are: \n",
            "         v1                                                 v2 Unnamed: 2  \\\n",
            "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
            "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
            "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
            "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
            "5571   ham                         Rofl. Its true to its name        NaN   \n",
            "\n",
            "     Unnamed: 3 Unnamed: 4  \n",
            "5567        NaN        NaN  \n",
            "5568        NaN        NaN  \n",
            "5569        NaN        NaN  \n",
            "5570        NaN        NaN  \n",
            "5571        NaN        NaN  \n"
          ]
        }
      ],
      "source": [
        "#Top and Botton 5 rows of car price prediction dataset\n",
        "print(\"Top 5 rows of the dataset are: \\n\",df.head())\n",
        "print(\"\\n\\nBottom 5 rows of the dataset are: \\n\",df.tail())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9b2bce7",
      "metadata": {
        "id": "b9b2bce7"
      },
      "source": [
        "The Porter stemming algorithm (or ‘Porter stemmer’) is a process for removing the commoner morphological and inflexional endings from words in English. Its main use is as part of a term normalisation process that is usually done when setting up Information Retrieval systems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2ae884da",
      "metadata": {
        "id": "2ae884da"
      },
      "outputs": [],
      "source": [
        "ps=PorterStemmer()\n",
        "lemmatize=WordNetLemmatizer()\n",
        "corpus=[]\n",
        "for i in range(0,len(df)):\n",
        "  review=re.sub('[^a-zA-Z]', ' ', df['v2'][i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "\n",
        "  review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc43ccdc",
      "metadata": {
        "id": "cc43ccdc"
      },
      "source": [
        "CountVectorizer is a great tool provided by the scikit-learn library in Python. It is used to transform a given text into a vector on the basis of the frequency (count) of each word that occurs in the entire text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6023c904",
      "metadata": {
        "id": "6023c904"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=2500)\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "y=pd.get_dummies(df['v1'])\n",
        "y=y.iloc[:,1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d0efe08d",
      "metadata": {
        "id": "d0efe08d"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "22d8b7f0",
      "metadata": {
        "id": "22d8b7f0"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "spam_detect_model = MultinomialNB().fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cb9e43de",
      "metadata": {
        "id": "cb9e43de"
      },
      "outputs": [],
      "source": [
        "y_pred=spam_detect_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "98f4e18b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98f4e18b",
        "outputId": "c39354c2-bf80-4b2b-e757-0090f2481923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[943   6]\n",
            " [  9 157]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "print(confusion_matrix(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "dacd3f89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dacd3f89",
        "outputId": "721cf6aa-8ad6-402f-8a9d-c74e47294bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score 0.9865470852017937\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2dd6d301",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dd6d301",
        "outputId": "d7e5a982-689e-4f6f-f9a1-c93cbc82f8fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report:               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.99      0.99      0.99       949\n",
            "        True       0.96      0.95      0.95       166\n",
            "\n",
            "    accuracy                           0.99      1115\n",
            "   macro avg       0.98      0.97      0.97      1115\n",
            "weighted avg       0.99      0.99      0.99      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Classification report: {}\".format(classification_report(y_test,y_pred)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}